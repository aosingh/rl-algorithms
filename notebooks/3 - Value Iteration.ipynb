{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value iteration \n",
    "\n",
    "Value iteration is a method of computing the value of an optimal policy.\n",
    "The basic algorithm is given below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let \n",
    "1. $S$ be the set of states, \n",
    "2. $v$ be the value function. We denote the $i^{th}$ iteration of the value function using $v^i$.\n",
    "3. $C(s, a)$ denote the contribution function which is a function of the state s and action(decision) a. It returns the reward in state s when the agent takes action a\n",
    "4. $\\gamma$ denote the discount factor $0 < \\gamma < 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Step 0. Initialization**:\n",
    "\\begin{align}\n",
    "        \\text{Set }v^0(s) = 0  :      \\forall{s} \\text{ }\\epsilon\\text{ }S\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "         \\text{Fix a tolerance parameter } \\epsilon > 0\n",
    "\\end{align}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1. For each ${s} \\text{ }\\epsilon\\text{ }S$:**\n",
    "\\begin{align}\n",
    "    v^n(s) = max_{a \\text{ }\\epsilon\\text{ }A}(C(s, a) + \\gamma \\sum_{s^{\\prime} \\text{ }\\epsilon\\text{ }S} P(s^{\\prime} |s, a)v^{n-1}(s^{\\prime}))\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2.**\n",
    "\\begin{align}\n",
    "   \\text{if } || v^{n} - v^{n-1}|| < \\epsilon(1 - \\gamma)/2\\gamma \\text{, let } \\pi_{\\epsilon} \\text{ be the resulting policy which solves the equation mentioned at Step 1, and let } v_{\\epsilon} = v_{n} \\text{ and stop.}\n",
    "\\end{align}\n",
    "\\begin{align}\n",
    "    \\text{else set } n = n + 1 \\text{ and go to Step 1}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that we stop the algorithm when $$|| v^{n} - v^{n-1}|| < \\epsilon(1 - \\gamma)/2\\gamma $$\n",
    "This is when the value function converges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $||v||$ is the max-norm defined by $$||v|| = max_{s}|v(s)|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "Consider a 2 stage Markov chain with the following one step transition matrix\n",
    "\n",
    "\\begin{equation*}\n",
    "    P = \\begin{vmatrix}\n",
    "    0.7 & 0.3 \\\\\n",
    "    0.05 & 0.95\n",
    "    \\end{vmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Contribution from each transition from state $i \\text{ } \\epsilon \\{1, 2\\}$ to state $j \\text{ } \\epsilon \\{1, 2\\}$ is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "C = \\begin{vmatrix}\n",
    "10 & 30 \\\\\n",
    "20 & 5\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply the value iteration algorithm for an infinite horizon problem. \n",
    "Please note that, for this exercise, we are not choosing a decision so, there won't be any maximisation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "class ValueIterationSimulator:\n",
    "    \"\"\"\n",
    "    This class is a simulation of the steps that we do to perform Value iteration.\n",
    "    \"\"\"\n",
    "    def __init__(self, states, C, P, gamma, initial_v):\n",
    "        \"\"\"\n",
    "        States : List(int) = A sequence of states. For e.g. [1, 2]\n",
    "        \n",
    "        C : List[List(int)] = The Contribution from each transition within the states. \n",
    "                              So, for n states this will n x n matrix\n",
    "        \n",
    "        P : List[List(int)] = The transition probablity matrix. \n",
    "        \n",
    "        gamma : int = Discount factor.\n",
    "        \n",
    "        initial_v : dict(int, int) = The initial estimate of the value function for each state. \n",
    "        \n",
    "        \"\"\"\n",
    "        self.states = states\n",
    "        self.C = C \n",
    "        self.P = P\n",
    "        self.gamma = gamma \n",
    "        self.v = defaultdict(dict)\n",
    "        # Set the initial estimate of the value function for each state\n",
    "        for state, init_estimate in initial_v.items():\n",
    "            self.v[0][state] = init_estimate\n",
    "    \n",
    "    def start(self, num_of_iterations=50):\n",
    "        for i in range(1, num_of_iterations+1):\n",
    "            for x in self.states:\n",
    "                expected_contribution = sum(C[x-1])/len(C[x-1])\n",
    "                expected_values = self.gamma * sum([self.P[x-1][y-1]*self.v[i-1][y] for y in self.states])\n",
    "                self.v[i][x] = expected_contribution + expected_values\n",
    "    \n",
    "    \n",
    "    def plot_value_function(self, state=1, num_of_values=50):\n",
    "        X = [x for x in range(0, num_of_values+1)]\n",
    "        Y = [value[state] for k, value in self.v.items()][0:num_of_values+1]\n",
    "        plt.plot(X, Y, 'ro')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a311940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "states = [1, 2]\n",
    "P = [[0,7, 0.3],\n",
    "     [0.05, 0.95]]\n",
    "C = [[10, 30],\n",
    "     [20, 5]]\n",
    "\n",
    "initial_v = {\n",
    "    1:0,\n",
    "    2:1000\n",
    "}\n",
    "gamma = 0.8\n",
    "\n",
    "value_iteration = ValueIterationSimulator(states, C, P, gamma, initial_v)\n",
    "value_iteration.start(num_of_iterations=1000)\n",
    "value_iteration.plot_value_function(state=2, num_of_values=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
